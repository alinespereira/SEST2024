---
title: "Web Scraping"
subtitle: "SEST 2024"
format: 
   revealjs:
      smaller: true
---

# Introdução

## O que é web scraping?

- Envolve acessar, baixar e organizar dados provenientes da web

- É o "terceiro braço" de pessoas que trabalham com ciência de dados

- Em português, "raspagem de dados"

- Não confundir com web crawling

## Por que web scraping?

Tudo o que você vê na internet pode se transformar dados para analisar!

```{r}
knitr::include_graphics("img/matrix.gif")
```

# Política do web scraping

## Cuidados

- Risco de derrubar ou comprometer a estabilidade do site

- Risco de ser processado

- Risco de cometer um crime

```{r}
knitr::include_graphics("img/mufasa.gif")
```

## Quando usar

- Quando precisamos coletar um volume grande de dados da internet

## Quando não usar

- Existem formas mais simples de obter os dados (API, base de dados, etc.)

- Os termos de uso do site não nos permitem fazer isso

- As informações do site não são públicas


# Fluxo do Web Scraping 

##

```{r fluxo-ws}
knitr::include_graphics("img/cycle.png")
```

## Tipos de problemas

- **APIs disponíveis**: o site fornece uma forma estruturada e documentada para acessar as páginas (com ou sem necessidade de fazer login).

- **HTML estático**: o site não fornece uma forma estruturada de acessar as páginas, e as páginas são geradas de forma estática (carregam sem necessidade de usar um navegador).

- **APIs escondidas**: o site não fornece uma forma estruturada e documentada para acessar as páginas, mas internamente é alimentado por uma API não documentada, que podemos descobrir e usar.

- **HTML dinâmico**: o site não fornece uma forma estruturada de acessar as páginas, e as páginas são geradas de forma dinâmica.


## APIs

:::: {.columns}

::: {.column width="45%"}
#### 1. Acessar

- Instruções de acesso na **documentação** da API.
- Geralmente envolve obter um **token** de acesso, que funciona como uma senha.

#### 2. Coletar

- Geralmente são requisições do tipo **GET**.
- Pode ou não possuir parâmetros para acessar as informações.
- O resultado geralmente vem num arquivo **json**.
:::

::: {.column width="10%"}

:::


::: {.column width="45%"}
#### 3. Inserir

- Geralmente são requisições do tipo **POST**.
- Necessariamente possui parâmetros para enviar informações ao servidor.

#### Pacotes

R: `httr` ou `httr2`

Python: `requests`
:::

::::


## Exemplo: Brasil API

```{r}
knitr::include_graphics("img/cat.gif")
```

## APIs escondidas

- Nem sempre a API estará documentada

- Neste caso, precisamos descobrir sua existência

- Técnicas mais importantes do profissional de raspagem:

> Inspecionar elemento

> Aba Network

## Exemplo: globoesporte

```{r}
knitr::include_graphics("img/cat.gif")
```


## HTML

- HTML (Hypertext Markup Language) é uma linguagem de marcação cujo uso é a criação de páginas web. 

- Por trás de todo site há pelo menos um arquivo .html.

```{r, echo=FALSE}
knitr::include_graphics("img/html1.png")
```


## HTML

- Todo arquivo HTML pode ser dividido em seções que definirão diferentes aspectos da página. 
- `<head>` descreve metadados, enquanto `<body>` é o corpo da página.

```{r, echo=FALSE}
knitr::include_graphics("img/html2.png")
```

## HTML

- Tags (head, body, h1, p, ...) demarcam as seções e sub-seções

- enquanto atributos (charset, style, ...) mudam como essas seções são renderizadas pelo navegador.

```{r, echo=FALSE}
knitr::include_graphics("img/html3.png")
```

## HTML

O HTML do exemplo, na verdade, é isso aqui:

```{r, echo=FALSE}
knitr::include_graphics("img/html_exemplo_tree_paifilho.png")
```

## XPath - XML Path Language

- Exemplo: coletando todas as tags `<p>` (parágrafos)

```{r, eval = FALSE, echo = TRUE}
library(xml2)

# Ler o HTML
html <- read_html("img/html_exemplo.html")

# Coletar todos os nodes com a tag <p>
nodes <- xml_find_all(html, "//p")

# Extrair o texto contido em cada um dos nodes
text <- xml_text(nodes)
text
```

## Exemplos: html + xpath

```{r}
knitr::include_graphics("img/cat.gif")
```

## Outras técnicas de Web Scraping

- APIs com autenticação: API keys

- Páginas com Login: requisições com headers + cookies

- Navegar via CSS Path

- Captchas: modelos que quebram captchas

- Páginas dinâmicas: selenium